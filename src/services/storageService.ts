
import { S3Client, PutObjectCommand, GetObjectCommand } from "@aws-sdk/client-s3";
import { getSignedUrl } from "@aws-sdk/s3-request-presigner";

// Initialize S3 Client
// Note: In a real production app, you might use a pre-signed URL generated by a backend lambda
// to avoid exposing Write credentials in the frontend. 
// However, for this "Serverless/Static" requirement, we use direct SDK with specific IAM user keys
// meant for this bucket only.
const s3Client = new S3Client({
    region: (import.meta.env.VITE_AWS_REGION || "us-east-1").trim(),
    credentials: {
        accessKeyId: (import.meta.env.VITE_AWS_ACCESS_KEY_ID || "").trim(),
        secretAccessKey: (import.meta.env.VITE_AWS_SECRET_ACCESS_KEY || "").trim(),
    },
});

const BUCKET_NAME = (import.meta.env.VITE_AWS_BUCKET_NAME || "pdfmaster-upload-bucket").trim();

// Check if keys are present
const hasKeys = !!(import.meta.env.VITE_AWS_ACCESS_KEY_ID?.trim() && import.meta.env.VITE_AWS_SECRET_ACCESS_KEY?.trim());

/**
 * Uploads a file to S3 and returns the object key.
 */
export async function uploadFile(file: File): Promise<string> {
    if (!hasKeys) {
        console.warn("AWS Credentials missing. Using Local Simulation Mode.");
        // Simulate network delay
        await new Promise(resolve => setTimeout(resolve, 1500));
        return `simulated-upload-${Date.now()}.pdf`;
    }

    // Generate a unique file name
    const timestamp = Date.now();
    const fileExtension = file.name.split('.').pop();
    const key = `uploads/${timestamp}-${Math.random().toString(36).substring(7)}.${fileExtension}`;

    const command = new PutObjectCommand({
        Bucket: BUCKET_NAME,
        Key: key,
        Body: file,
        ContentType: file.type,
        // Start with 30-day expiry logic handled by bucket lifecycle policy, 
        // or we can tag it.
        Metadata: {
            originalName: file.name,
            uploadedAt: timestamp.toString()
        }
    });

    try {
        await s3Client.send(command);
        return key;
    } catch (error) {
        console.error("Upload failed:", error);
        throw new Error("Failed to upload file to cloud storage.");
    }
}


/**
 * Generates a Secure Pre-Signed URL for the file.
 * This URL will only be valid for a short duration (e.g., 10 minutes).
 */
export async function getSecureDownloadUrl(key: string): Promise<string> {
    if (key.startsWith('simulated-')) {
        return "javascript:alert('DEMO MODE: Valid AWS Credentials are required to download this file through the Secure Vault tunnel.')";
    }

    if (!hasKeys) {
        throw new Error("AWS Credentials missing. Cannot generate secure download link.");
    }

    const command = new GetObjectCommand({
        Bucket: BUCKET_NAME,
        Key: key,
    });

    try {
        // Generate a pre-signed URL that expires in 10 minutes (600 seconds)
        const url = await getSignedUrl(s3Client, command, { expiresIn: 600 });
        return url;
    } catch (error) {
        console.error("Failed to generate pre-signed URL:", error);
        throw new Error("Secure download link generation failed.");
    }
}

/**
 * Generates the Public URL for the file.
 * @deprecated Use getSecureDownloadUrl for better security.
 */
export function getPublicUrl(key: string): string {
    if (key.startsWith('simulated-')) {
        return "javascript:alert('DEMO MODE: Valid AWS Credentials are required to download this file from the Secure Cloud Vault.')";
    }

    const region = (import.meta.env.VITE_AWS_REGION || "us-east-1").trim();
    // Standard S3 URL format
    return `https://${BUCKET_NAME}.s3.${region}.amazonaws.com/${key}`;
}
